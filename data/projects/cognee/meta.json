{
  "name": "cognee",
  "repository_url": "https://github.com/topoteretes/cognee",
  "stars": 12200,
  "primary_language": "Python",
  "description": "AI代理记忆知识引擎，仅需6行代码即可将原始数据转化为持久化的动态AI记忆",
  "last_updated": "2026-02-04",
  "paper": {
    "exists": true,
    "title": "Optimizing the interface between knowledge graphs and LLMs",
    "venue": "Research Paper",
    "year": 2025,
    "url": "https://arxiv.org/abs/2505.24478"
  },
  "benchmarks": {},
  "innovations": {
    "key_features": [
      "ECL（提取、认知化、加载）流程替代传统 RAG",
      "知识图谱 + 向量混合架构（Graph+Vector Hybrid）",
      "支持 30+ 数据源的 Pythonic 数据管道",
      "模块化任务系统和可定制管道",
      "多租户隔离和权限系统",
      "8+ 向量数据库和 3+ 图数据库支持",
      "10+ LLM 提供商统一集成（litellm + Instructor）",
      "本地优先设计，零配置开发环境"
    ],
    "improvements": [
      "降低开发者成本和基础设施成本",
      "将数据互联替代传统数据库查询",
      "通过图和向量混合检索提升准确性",
      "支持本地部署和多种数据库后端切换",
      "提供企业级多租户和访问控制"
    ],
    "user_value": [
      "6 行代码即可构建 AI 记忆系统",
      "灵活的知识图谱生成和查询",
      "支持文本、对话、文件、图片、音频等多种数据类型",
      "降低运维成本（本地 SQLite+Kuzu+LanceDB 零成本）",
      "8 种搜索类型满足不同检索需求",
      "生产就绪的监控和日志系统",
      "活跃的开源社区和详细文档支持"
    ]
  },
  "use_cases": {
    "scenarios": [
      "企业知识管理系统",
      "AI 代理持久化记忆",
      "增强型 RAG 应用",
      "代码理解和搜索",
      "研究论文分析",
      "客户支持知识库",
      "多模态数据处理（文档、图片、音频）",
      "对话历史和上下文管理"
    ],
    "companies": [
      "被 AI 初创公司用于知识管理",
      "集成到多个 AI Agent 框架",
      "用于企业文档智能化",
      "研究机构的论文分析工具"
    ]
  },
  "tech_stack": {
    "storage": [
      "Graph Database",
      "Vector Database",
      "Unified Engine"
    ],
    "frameworks": [
      "Python",
      "Pythonic Pipelines",
      "CLI Tool"
    ],
    "languages": [
      "Python"
    ],
    "embedding_models": [
      "Multiple LLM providers"
    ]
  },
  "cloud_needs": {
    "storage": {
      "types": [
        "Graph+Vector Hybrid",
        "Multi-format storage"
      ],
      "requirements": [
        "30+ data source integrations",
        "Unified knowledge engine"
      ]
    },
    "compute": {
      "embedding": true,
      "gpu_needed": false,
      "estimated_requirements": "4-16 vCPUs for processing pipelines"
    },
    "deployment": {
      "complexity": 6,
      "containerized": true,
      "orchestration": [
        "Docker",
        "Local UI"
      ]
    },
    "storage_detail": {
      "vector_storage": {
        "solution": "多后端向量数据库(默认LanceDB)",
        "database": "LanceDB (默认) / ChromaDB / PGVector / Qdrant / Weaviate / Milvus",
        "vector_dimension": 384,
        "index_type": "HNSW",
        "evidence": "pyproject.toml: lancedb>=0.24.0为核心依赖, fastembed<=0.6.0提供本地嵌入(默认384维); 可选pgvector>=0.3.5, chromadb>=0.6; VectorDBInterface抽象层支持6+后端"
      },
      "primary_database": {
        "type": "关系数据库(SQLite默认/PostgreSQL可选)",
        "min_version": "SQLite 3.x / PostgreSQL 12+",
        "required_extensions": [
          "PGVector (PostgreSQL向量扩展, 可选)"
        ],
        "connection_pooling": {
          "driver": "SQLAlchemy异步连接 (aiosqlite/asyncpg)",
          "max_connections": "PostgreSQL默认连接池"
        },
        "evidence": "pyproject.toml: sqlalchemy>=2.0.39, aiosqlite>=0.20.0为核心依赖; postgres可选: psycopg2>=2.9.10, asyncpg>=0.30.0; Alembic做数据库迁移"
      },
      "graph_database": {
        "required": true,
        "type": "Kuzu (默认, 嵌入式) / Neo4j / Neptune",
        "evidence": "pyproject.toml: kuzu==0.11.3为核心依赖; neo4j>=5.28.0为可选; GraphDBInterface支持3种后端"
      },
      "cache": {
        "type": "Redis (可选) / DiskCache / fakeredis (默认)",
        "min_version": "Redis 5.0+ (可选)",
        "required_modules": [
          "diskcache>=5.6.3",
          "fakeredis[lua]>=2.32.0 (默认)",
          "redis>=5.0.3 (可选)"
        ],
        "evidence": "pyproject.toml: fakeredis为核心依赖(内存模拟Redis); 可选redis>=5.0.3; diskcache>=5.6.3"
      },
      "data_scale": {
        "estimated_total": "1K用户约90GB, 10K用户约900GB",
        "per_user_avg": "原始数据+处理后数据+缓存约90MB/用户",
        "evidence": "架构文档的存储需求分析表"
      },
      "performance": {
        "vector_search_latency": "<100ms (top-10, P99)",
        "qps_target": "10-500 QPS (按规模)",
        "p95_latency": "<500ms (含LLM调用)",
        "concurrent_connections": "50-1000"
      }
    },
    "compute_detail": {
      "cpu": {
        "min_vcpu": 4,
        "recommended_vcpu": 8,
        "workload_type": "IO密集(多数据库操作) + CPU密集(文档处理和图提取)"
      },
      "memory": {
        "min_gb": 8,
        "recommended_gb": 16,
        "memory_intensive_ops": [
          "Kuzu图遍历",
          "文档处理管道",
          "fastembed模型加载",
          "onnxruntime推理"
        ],
        "oom_risk": "中等"
      },
      "gpu": {
        "required": false,
        "recommended": false,
        "use_case": "不需要",
        "cuda_dependency": {
          "has_direct_cuda": false,
          "custom_cuda_kernels": false,
          "gpu_libraries": [
            "onnxruntime (CPU版本, 用于fastembed)"
          ],
          "evidence": "pyproject.toml: onnxruntime<=1.22.1和fastembed<=0.6.0为核心依赖, 均默认CPU运行; uv.lock中nvidia-*包为PyTorch传递依赖(transformers可选扩展); 核心嵌入使用fastembed(ONNX Runtime CPU); 无直接CUDA代码"
        }
      },
      "scalability": {
        "horizontal_scaling": true,
        "stateless": true,
        "auto_scaling_metrics": [
          "CPU利用率",
          "请求延迟",
          "任务队列深度"
        ]
      },
      "serverless": {
        "suitable": false,
        "cold_start_tolerance": "不适合",
        "reasons": [
          "需加载fastembed模型",
          "需持久数据库连接",
          "管道处理可能耗时较长"
        ]
      },
      "concurrency": {
        "model": "异步(asyncio)",
        "async_framework": "FastAPI + asyncio",
        "message_queue": {
          "required": false,
          "systems": [
            "Redis (可选, 用于缓存)",
            "Modal (可选, 分布式执行)"
          ]
        },
        "websocket": true,
        "streaming": true
      }
    },
    "ascend_npu": {
      "compatibility_level": "容易适配",
      "framework_analysis": {
        "framework": "ONNX Runtime (fastembed) + 可选PyTorch (transformers)",
        "framework_version": "onnxruntime<=1.22.1",
        "ascend_support": true,
        "cann_version": "CANN 8.0+ (onnxruntime-cann)"
      },
      "migration": {
        "effort_level": "低",
        "blockers": [],
        "code_changes_required": [
          "安装onnxruntime-cann替代onnxruntime以启用昇腾NPU加速fastembed",
          "如使用transformers可选依赖: 安装torch-npu替代cuda版PyTorch"
        ]
      },
      "recommendation": "Cognee核心使用fastembed(基于ONNX Runtime)做嵌入, ONNX Runtime已有华为昇腾CANN后端支持(onnxruntime-cann)。只需替换onnxruntime包为onnxruntime-cann即可在昇腾NPU上加速嵌入计算, 代码无需修改。LLM调用走外部API不受影响。"
    },
    "external_services": {
      "llm": {
        "providers": [
          "OpenAI (推荐)",
          "Anthropic Claude",
          "Google Gemini",
          "Mistral",
          "Groq",
          "Ollama (本地)",
          "AWS Bedrock"
        ],
        "embedding_models": [
          "fastembed/bge-base-en-v1.5 (本地, 384维, 默认)",
          "text-embedding-3-small/large (OpenAI)",
          "nomic-embed-text (Ollama本地)"
        ],
        "local_model_support": true,
        "cost_optimization": [
          "默认本地fastembed零成本嵌入",
          "支持Groq低延迟低成本LLM",
          "管道缓存避免重复处理",
          "使用litellm统一API降低切换成本"
        ]
      }
    },
    "deployment_detail": {
      "complexity": 5,
      "docker": {
        "available": true,
        "image_size": "约1.2GB",
        "multi_stage_build": true
      },
      "kubernetes": {
        "required": false,
        "recommended": true,
        "helm_available": true
      },
      "configuration": {
        "env_vars_count": 25,
        "secrets_count": 5,
        "complexity_level": "中等"
      },
      "observability": {
        "metrics_export": true,
        "structured_logging": true,
        "health_checks": true
      }
    }
  },
  "categories": {
    "tech_approach": [
      "Graph+Vector Hybrid",
      "Easy Integration",
      "Multi-source"
    ],
    "use_case": [
      "Knowledge Management",
      "Data Integration",
      "Enterprise AI"
    ]
  },
  "value_propositions": [
    {
      "name": "6行代码知识引擎",
      "description": "通过ECL(提取、认知化、加载)流程替代传统RAG,采用知识图谱+向量混合架构(Graph+Vector Hybrid)和Pythonic数据管道,支持30+数据源集成和8种搜索类型,实现6行代码即可构建AI记忆系统的极简开发体验。"
    },
    {
      "name": "多租户混合检索引擎",
      "description": "支持8+向量数据库(LanceDB等)和3+图数据库(Kuzu、Neo4j等)统一集成,采用10+ LLM提供商(litellm+Instructor)和本地优先设计(SQLite+Kuzu+LanceDB零成本),通过模块化任务系统和多租户隔离实现企业级知识管理和权限控制。"
    }
  ],
  "huawei_cloud": {
    "overall_difficulty": "中等",
    "recommended_services": {
      "database": {
        "primary": "华为云RDS for PostgreSQL (生产) / SQLite (开发)",
        "vector_solution": "LanceDB自托管 或 华为云GaussDB+向量检索 或 PGVector on RDS"
      },
      "cache": "华为云DCS Redis (可选, 生产环境推荐)",
      "compute": {
        "primary": "华为云ECS (4核8GB起步)",
        "ai_acceleration": "无需(fastembed CPU足够)"
      },
      "middleware": {
        "load_balancer": "华为云ELB",
        "object_storage": "华为云OBS (替代S3)"
      }
    },
    "cost_estimation": {
      "small_scale": {
        "description": "1000用户, 开发/小型生产",
        "monthly_cost": "¥1,500-2,500",
        "breakdown": {
          "ECS_4c8g": "¥400",
          "RDS_PostgreSQL_2c4g": "¥300",
          "EVS_100GB": "¥60",
          "LLM_API": "¥500",
          "带宽_10Mbps": "¥150"
        }
      },
      "medium_scale": {
        "description": "10000用户, 生产环境",
        "monthly_cost": "¥12,000-18,000",
        "breakdown": {
          "ECS_8c16g_x4": "¥3,200",
          "RDS_PostgreSQL_4c8g": "¥800",
          "DCS_Redis_2g": "¥200",
          "ELB": "¥300",
          "LLM_API": "¥5,000",
          "OBS_1TB": "¥150",
          "带宽_50Mbps": "¥750"
        }
      }
    },
    "special_requirements": [
      "默认Kuzu图数据库嵌入式运行无需额外服务",
      "如升级到Neo4j需自托管在ECS上",
      "S3存储后端需改为华为云OBS(兼容S3 API, 代码修改极少)",
      "fastembed使用ONNX Runtime, 可使用onnxruntime-cann加速"
    ],
    "architecture_recommendations": [
      "开发阶段使用默认配置: SQLite+LanceDB+Kuzu零成本运行",
      "生产环境切换到: PostgreSQL+PGVector+Kuzu/Neo4j",
      "华为云OBS替代AWS S3作为文件存储后端(修改STORAGE_BACKEND配置)",
      "使用华为云CCE(容器引擎)部署Helm Chart",
      "如需国内LLM可配置litellm对接华为云盘古大模型"
    ]
  }
}