{
  "name": "memtrace",
  "repository_url": "https://github.com/Basekick-Labs/memtrace",
  "stars": 5,
  "primary_language": "Go",
  "description": "LLM不可知的AI代理记忆层，无需嵌入或向量数据库 - 仅提供快速、结构化、时间序列记忆，可作为纯文本使用",
  "last_updated": "2026-02-07",
  "paper": {
    "exists": false,
    "title": "",
    "venue": "",
    "year": 0,
    "url": ""
  },
  "benchmarks": {},
  "tech_stack": {
    "storage": [
      "Arc Database",
      "Time-series"
    ],
    "frameworks": [
      "Go",
      "Python SDK",
      "TypeScript SDK",
      "MCP Server"
    ],
    "languages": [
      "Go"
    ],
    "embedding_models": []
  },
  "cloud_needs": {
    "mandatory_cloud_services": [
      {
        "type": "Arc Time-Series Database",
        "providers": [
          "Self-hosted Arc",
          "Huawei GaussDB(for Influx) as alternative",
          "InfluxDB Cloud (adapter required)",
          "TimescaleDB (adapter required)"
        ],
        "purpose": "Time-series memory storage with Parquet backend",
        "cost": "$0-3500/month",
        "necessity": "Mandatory"
      }
    ],
    "optional_cloud_services": [
      {
        "type": "Object Storage",
        "providers": [
          "Huawei OBS",
          "AWS S3",
          "Google Cloud Storage"
        ],
        "purpose": "Backup for SQLite metadata and Arc Parquet files",
        "cost": "$10-200/month",
        "necessity": "Optional"
      }
    ],
    "storage": {
      "types": [
        "Arc Time-Series Database",
        "SQLite Metadata",
        "Block Storage (SSD)"
      ],
      "requirements": [
        "Temporal queries",
        "Session context",
        "No vector DB",
        "Persistent volumes for SQLite",
        "Parquet columnar storage"
      ],
      "estimated_size": {
        "small": "< 1GB (1K memories/day)",
        "medium": "10-100GB (100K memories/day)",
        "large": "100GB-1TB (1M+ memories/day)"
      },
      "compression": "5-10x via Parquet",
      "backup_strategy": "Daily SQLite backup + Arc Parquet file backup to S3/GCS/OBS",
      "graph_database": {
        "required": false,
        "note": "No graph database - uses time-series only"
      },
      "vector_database": {
        "required": false,
        "note": "No embeddings, no vector search - plain text temporal queries"
      },
      "object_storage": {
        "required": false,
        "use_case": "Backup only"
      }
    },
    "compute": {
      "embedding": false,
      "gpu_needed": false,
      "cpu_requirements": {
        "small": "2 vCPUs",
        "medium": "4-8 vCPUs",
        "large": "16-32 vCPUs"
      },
      "memory_requirements": {
        "minimum": "512MB RAM",
        "recommended": "2-4GB RAM",
        "peak_buffer": "100MB (10K record write buffer)"
      },
      "justification": "Go runtime efficiency, no ML workloads, write batching parallelism",
      "scaling": "Horizontal (stateless) + vertical (write throughput)"
    },
    "network": {
      "bandwidth": {
        "small": "< 100 Kbps (1-10 writes/sec)",
        "medium": "1-5 Mbps (10-100 writes/sec)",
        "large": "10-50 Mbps (100-1000 writes/sec)"
      },
      "latency_requirements": {
        "write": "< 100ms (buffered)",
        "query": "10-200ms (Arc SQL)",
        "session_context": "50-500ms (aggregation)"
      },
      "ports": {
        "api": "9100 (HTTP/HTTPS)",
        "arc_internal": "8000 (HTTP to Arc DB)"
      },
      "tls": "Recommended via reverse proxy (Nginx, Caddy)"
    },
    "database": {
      "primary": {
        "type": "Arc Time-Series Database",
        "deployment": "Self-hosted Docker or VM",
        "connection": "HTTP API with API key auth",
        "concurrency": "10 idle connections per instance",
        "alternatives": [
          "InfluxDB Cloud (adapter required)",
          "TimescaleDB (SQL adapter required)",
          "ClickHouse (medium effort)",
          "QuestDB (medium effort)"
        ]
      },
      "metadata": {
        "type": "SQLite",
        "size": "< 10MB",
        "persistence": "File-based, requires persistent volume",
        "ha_limitation": "Single-file, not HA-compatible",
        "ha_solution": "Migrate to PostgreSQL or MySQL (requires code changes)"
      }
    },
    "deployment": {
      "complexity": 4,
      "containerized": true,
      "orchestration": [
        "Docker",
        "Kubernetes",
        "Docker Compose (dev)"
      ],
      "deployment_models": {
        "single_vm": {
          "use_case": "Development, small teams",
          "cost": "$20-50/month",
          "specs": "4 vCPU, 4GB RAM"
        },
        "kubernetes": {
          "use_case": "Production, high availability",
          "cost": "$500-2000/month",
          "features": "Auto-scaling, rolling updates, health checks"
        },
        "hybrid_cloud": {
          "use_case": "Data sovereignty, compliance",
          "setup": "Memtrace in cloud + Arc on-premises via VPN"
        }
      },
      "not_recommended": [
        "Serverless/FaaS (Lambda, Cloud Functions) - requires persistent state",
        "Managed vector databases - unnecessary"
      ]
    },
    "cost_analysis": {
      "small_deployment": {
        "workload": "1-5 agents, 1K memories/day",
        "monthly_cost": "$16 (AWS t3.small + 10GB EBS)"
      },
      "medium_deployment": {
        "workload": "10-50 agents, 100K memories/day",
        "monthly_cost": "$153 (2x t3.medium + t3.large Arc + ALB)"
      },
      "large_deployment": {
        "workload": "100+ agents, 1M memories/day",
        "monthly_cost": "$1,326 (5x t3.xlarge + 3x r6g.xlarge Arc cluster)"
      },
      "comparison_vs_vector_solutions": {
        "memtrace": "$153/month (100K memories/day)",
        "pinecone": "$120-480/month (infra + embedding API)",
        "weaviate_cloud": "$150-600/month (infra + embedding API)",
        "savings": "50-70% cheaper than vector solutions"
      },
      "cost_drivers": [
        "No embedding API costs",
        "No vector storage overhead (10-50x smaller)",
        "Simple architecture = lower ops overhead"
      ]
    },
    "operational_requirements": {
      "monitoring": {
        "health_endpoints": [
          "/health (liveness)",
          "/ready (Arc connectivity)"
        ],
        "recommended_metrics": [
          "memtrace_writes_total",
          "memtrace_queries_total",
          "memtrace_buffer_size",
          "memtrace_arc_latency_seconds"
        ],
        "logging": "Structured JSON to stdout (ELK, Datadog, CloudWatch)"
      },
      "backup_recovery": {
        "rto": "< 15 minutes (container restart + volume mount)",
        "rpo": "1 second (flush interval) to 24 hours (backup interval)",
        "sqlite_backup": "Daily file copy",
        "arc_backup": "Parquet files to S3/GCS"
      },
      "configuration": {
        "method": "TOML file + environment variables",
        "secrets": "AWS Secrets Manager, GCP Secret Manager, Vault",
        "hot_reload": "Not supported - requires restart"
      }
    },
    "security_compliance": {
      "encryption": {
        "at_rest": "Not built-in - use encrypted EBS/GCE volumes",
        "in_transit": "TLS termination at load balancer",
        "arc_connection": "Configure HTTPS for Arc endpoint"
      },
      "authentication": "API key-based (bcrypt hashed, mtk_ prefix)",
      "authorization": "Organization-level isolation, no RBAC",
      "compliance": {
        "gdpr": "API supports export, deletion requires custom implementation",
        "hipaa": "Not certified - requires custom hardening",
        "soc2": "API key baseline, structured logs, gaps in access review"
      }
    },
    "scalability": {
      "horizontal_scaling": {
        "design": "Stateless, load-balanced",
        "write_throughput": {
          "1_instance": "500-1000 writes/sec",
          "3_instances": "1500-3000 writes/sec",
          "10_instances": "5000-10000 writes/sec (requires Arc cluster)"
        }
      },
      "data_volume_scaling": {
        "< 1M_memories": "< 50ms query latency, single Arc node",
        "1M-10M_memories": "50-200ms latency, SSD storage",
        "10M-100M_memories": "100-500ms latency, Arc cluster + partitioning",
        "> 100M_memories": "500ms+ latency, time-based partitioning + archival"
      },
      "limitations": [
        "SQLite single-file limits HA (migrate to PostgreSQL for HA)",
        "Arc dependency (tight coupling, consider adapter layer)"
      ]
    },
    "key_differentiators": [
      "No GPU required (zero ML workloads)",
      "No embedding infrastructure (no OpenAI/Cohere API dependency)",
      "No vector database (simpler architecture, lower costs)",
      "LLM-agnostic (works with any model without re-indexing)",
      "Temporal-first (time-series DB optimized for 'what happened when')",
      "50-70% cheaper than vector solutions"
    ],
    "storage_detail": {
      "vector_storage": {
        "solution": "不需要",
        "database": "Arc (时序数据库，无向量)",
        "scale_requirement": "千万级时序事件"
      },
      "primary_database": {
        "type": "Arc / SQLite",
        "min_version": "Arc latest",
        "required_extensions": [],
        "schema_isolation": "多租户Database隔离",
        "connection_pool": true
      },
      "graph_database": {},
      "cache": {
        "type": "内存缓存",
        "required_modules": [],
        "persistence_required": false
      },
      "data_scale": {
        "estimated_total": "10GB-500GB",
        "per_user_avg": "100MB",
        "growth_rate": "日增1GB (时序事件)",
        "max_single_record": "1MB"
      },
      "performance": {
        "vector_search_latency": "不适用",
        "qps_target": "10000+",
        "p95_latency": "<50ms",
        "concurrent_connections": 5000
      }
    },
    "compute_detail": {
      "cpu": {
        "min_vcpu": 2,
        "recommended_vcpu": 4,
        "workload_type": "CPU密集型",
        "instruction_set_requirements": []
      },
      "memory": {
        "min_gb": 2,
        "recommended_gb": 8,
        "memory_intensive_ops": [
          "时序数据批量写入",
          "查询缓存"
        ],
        "oom_risk": "低"
      },
      "gpu": {
        "required": false,
        "recommended": false,
        "use_case": "不需要",
        "cuda_dependency": {
          "has_direct_cuda": false,
          "cuda_version": null,
          "cudnn_required": false,
          "tensorrt_used": false,
          "custom_cuda_kernels": false,
          "gpu_libraries": []
        }
      },
      "scalability": {
        "horizontal_scaling": true,
        "stateless": true,
        "session_persistence_required": false,
        "auto_scaling": {
          "supported": true,
          "trigger_metrics": [
            "CPU",
            "QPS"
          ],
          "scale_down_safe": true
        }
      },
      "serverless": {
        "suitable": true,
        "cold_start_tolerance": "<1s",
        "cold_start_actual": "<500ms",
        "state_management": "DB状态",
        "reasons": [
          "Go编译型语言启动快",
          "无状态设计"
        ]
      },
      "concurrency": {
        "model": "异步",
        "async_framework": "Go goroutines",
        "message_queue": {
          "required": false
        },
        "long_connection": {
          "websocket": false,
          "sse": true,
          "streaming": false
        }
      }
    },
    "ascend_npu": {
      "compatibility_level": "不适用(无GPU需求)",
      "framework_analysis": {
        "framework": "Go",
        "framework_version": "1.25+",
        "ascend_support": true,
        "ascend_version": "N/A"
      },
      "migration": {
        "effort_level": "低(1-2天)",
        "code_changes_required": [],
        "testing_effort": "无需特殊测试"
      },
      "blockers": [],
      "performance_expectation": {
        "expected_vs_gpu": "不适用",
        "bottlenecks": []
      },
      "recommendation": "Go服务无GPU依赖，直接部署到华为云ECS或CCI即可。"
    },
    "external_services": {
      "llm": {
        "required_providers": [
          "任意LLM"
        ],
        "optional_providers": [],
        "embedding_models": {
          "default": "不需要",
          "alternatives": [],
          "local_option": false
        },
        "llm_models": {
          "default": "可选任意",
          "alternatives": [],
          "local_option": true
        },
        "cost_optimization": [
          "时序存储压缩",
          "批量写入"
        ]
      },
      "object_storage": {
        "required": false
      }
    },
    "deployment_detail": {
      "complexity": 4,
      "containerized": true,
      "orchestration": [
        "Kubernetes",
        "Docker"
      ],
      "docker": {
        "available": true,
        "image_size": "20MB",
        "multi_stage_build": true,
        "base_image": "alpine"
      },
      "kubernetes": {
        "required": false,
        "recommended": true,
        "helm_chart_available": false,
        "manifests_available": false,
        "operators_available": false,
        "min_k8s_version": "1.24"
      },
      "configuration": {
        "env_vars_count": 8,
        "secrets_count": 2,
        "config_files": [
          "memtrace.toml"
        ],
        "complexity_level": "中等"
      },
      "observability": {
        "metrics_export": true,
        "structured_logging": true,
        "tracing_support": false,
        "health_checks": true
      },
      "upgrade": {
        "rolling_update_support": true,
        "blue_green_support": true,
        "migration_scripts_available": false,
        "backward_compatible": true
      }
    }
  },
  "categories": {
    "tech_approach": [
      "No Embeddings",
      "Time-series",
      "Plain Text"
    ],
    "use_case": [
      "Claude Code",
      "Cursor",
      "Windsurf",
      "Temporal Queries"
    ]
  },
  "value_propositions": [
    {
      "name": "零嵌入时序记忆架构",
      "description": "采用Arc时序数据库和无嵌入纯文本架构,消除向量数据库和嵌入API依赖,通过Parquet列式存储实现5-10倍压缩,相比向量解决方案节省50-70%成本(中型部署$153/月 vs Pinecone $120-480/月),零GPU需求和LLM无关设计。"
    },
    {
      "name": "快速结构化时间查询",
      "description": "基于Arc数据库的SQL时序查询实现10-200ms查询延迟和50-500ms会话上下文聚合,支持MCP Server、Python SDK、TypeScript SDK多接口部署,通过Go运行时效率和写批处理并行化,单实例可处理500-1000写入/秒。"
    }
  ],
  "huawei_cloud": {
    "overall_difficulty": "中等",
    "recommended_services": {
      "database": {
        "primary": "GaussDB(for Influx) 时序数据库 或 自建Arc on ECS",
        "vector_solution": "不需要"
      },
      "cache": "DCS Redis (可选，会话缓存)",
      "compute": {
        "primary": "CCE容器引擎 (K8s)",
        "ai_acceleration": "不需要",
        "auto_scaling": "CCE HPA"
      },
      "middleware": {
        "message_queue": "可选DMS Kafka (事件流)"
      },
      "network": {
        "vpc": true,
        "elb": true,
        "nat": false
      }
    },
    "cost_estimation": {
      "small_scale": {
        "description": "1000 agents，5000 events/min",
        "monthly_cost": "¥2,500-4,000",
        "breakdown": {
          "ECS 2核4G (Arc数据库)": "¥400",
          "CCE节点 2核4G x 2": "¥1,200",
          "ELB": "¥300",
          "DCS Redis 2GB": "¥200",
          "VPC/带宽": "¥400"
        }
      },
      "medium_scale": {
        "description": "1万 agents，5万 events/min",
        "monthly_cost": "¥10,000-15,000",
        "breakdown": {
          "GaussDB(for Influx) 通用型": "¥3,500",
          "CCE节点 4核8G x 4": "¥4,800",
          "ELB (性能型)": "¥800",
          "DCS Redis 8GB": "¥600",
          "VPC/带宽": "¥1,000",
          "DMS Kafka (可选)": "¥1,500"
        }
      }
    },
    "special_requirements": [
      "需要部署Arc时序数据库(开源项目)到ECS或使用GaussDB(for Influx)替代",
      "Arc数据库需要SSD存储以保证写入性能"
    ],
    "architecture_recommendations": [
      "时序数据库可用GaussDB(for Influx)替代Arc，获得托管服务优势",
      "Go服务编译后体积小、启动快，适合容器化部署",
      "建议使用CCE部署，配合HPA实现自动伸缩",
      "高频写入场景建议使用SSD云盘或本地SSD实例"
    ]
  }
}