{
  "name": "Memary",
  "repository_url": "https://github.com/kingjulio8238/Memary",
  "stars": 2600,
  "primary_language": "Python",
  "description": "自主智能体的开源记忆层，模拟人类记忆工作原理",
  "last_updated": "2025",
  "paper": {
    "exists": false,
    "title": "",
    "venue": "",
    "year": 0,
    "url": ""
  },
  "benchmarks": {},
  "tech_stack": {
    "storage": [
      "Neo4j",
      "FalkorDB",
      "Knowledge Graph"
    ],
    "frameworks": [
      "Python",
      "ReAct",
      "Dashboard"
    ],
    "languages": [
      "Python"
    ],
    "embedding_models": [
      "Ollama",
      "GPT-3.5-turbo",
      "GPT-4-vision"
    ]
  },
  "cloud_needs": {
    "storage": {
      "types": [
        "Knowledge Graph",
        "Memory Stream",
        "Entity Store"
      ],
      "requirements": [
        "Dual memory architecture",
        "Multi-agent support"
      ]
    },
    "compute": {
      "embedding": true,
      "gpu_needed": false,
      "estimated_requirements": "8-16 vCPUs for graph operations"
    },
    "deployment": {
      "complexity": 7,
      "containerized": true,
      "orchestration": [
        "Docker",
        "Neo4j/FalkorDB cluster"
      ]
    },
    "storage_detail": {
      "vector_storage": {
        "solution": "无直接向量数据库，依赖图数据库存储三元组关系",
        "database": "无（可选集成Pinecone/Weaviate/Milvus）",
        "vector_dimension": 1536,
        "index_type": "N/A（图数据库索引）",
        "evidence": "requirements.txt中无向量数据库依赖；architecture.md明确说明'Memary不直接使用向量数据库,而是用图数据库存储三元组关系'"
      },
      "primary_database": {
        "type": "图数据库",
        "min_version": "Neo4j 5.17.0 / FalkorDB 1.0.8",
        "required_extensions": [
          "llama-index-graph-stores-neo4j==0.3.1",
          "llama-index-graph-stores-falkordb==0.2.1",
          "llama-index-graph-stores-nebula==0.3.0"
        ],
        "connection_pooling": {
          "configured": false,
          "evidence": "代码中通过llama-index的graph store适配器连接，无显式连接池配置"
        },
        "evidence": "requirements.txt: FalkorDB==1.0.8, neo4j==5.17.0; pyproject.toml列出相同依赖"
      },
      "graph_database": {
        "required": true,
        "type": "Neo4j 5.17.0 或 FalkorDB 1.0.8",
        "evidence": "requirements.txt明确列出neo4j==5.17.0和FalkorDB==1.0.8；架构核心基于知识图谱的Memory Stream和Entity Knowledge Store"
      },
      "cache": {
        "type": "无内置缓存",
        "min_version": "N/A",
        "required_modules": [],
        "evidence": "requirements.txt中无Redis/Memcached依赖；architecture.md建议启用Redis但未实现"
      },
      "data_scale": {
        "estimated_total": "1MB JSON/用户/年 + 10-100MB图数据/用户",
        "per_user_avg": "约11-101MB",
        "evidence": "architecture.md数据规模估算：JSON记忆1MB/用户/年，图数据库10-100MB/用户"
      },
      "performance": {
        "vector_search_latency": "N/A（不使用向量搜索）",
        "qps_target": "未明确",
        "p95_latency": "<100ms（图查询），<2s（ReAct推理）",
        "concurrent_connections": "5-100（取决于规模）"
      }
    },
    "compute_detail": {
      "cpu": {
        "min_vcpu": 2,
        "recommended_vcpu": 8,
        "workload_type": "图数据库查询密集型 + LLM API调用"
      },
      "memory": {
        "min_gb": 4,
        "recommended_gb": 16,
        "memory_intensive_ops": [
          "Neo4j/FalkorDB图遍历",
          "多跳推理子图合并",
          "Context Window管理"
        ],
        "oom_risk": "低（主要依赖外部LLM API和图数据库）"
      },
      "gpu": {
        "required": false,
        "recommended": false,
        "use_case": "不需要",
        "cuda_dependency": {
          "has_direct_cuda": false,
          "custom_cuda_kernels": false,
          "gpu_libraries": [],
          "evidence": "requirements.txt无torch/cuda相关依赖；核心代码不涉及GPU操作；仅dev/reranking实验notebook中出现CUDA依赖(llama-index-postprocessor-colbert-rerank)，但非主要功能路径"
        }
      },
      "scalability": {
        "horizontal_scaling": false,
        "stateless": false,
        "auto_scaling_metrics": [
          "CPU利用率",
          "图查询延迟"
        ]
      },
      "serverless": {
        "suitable": false,
        "cold_start_tolerance": "不适合",
        "reasons": [
          "依赖图数据库持久连接",
          "Streamlit有状态",
          "LLM上下文需要保持"
        ]
      },
      "concurrency": {
        "model": "同步",
        "async_framework": "Streamlit单线程",
        "message_queue": {
          "required": false,
          "systems": []
        },
        "websocket": false,
        "streaming": true
      }
    },
    "ascend_npu": {
      "compatibility_level": "不适用(无GPU需求)",
      "framework_analysis": {
        "framework": "无ML框架依赖",
        "framework_version": "N/A",
        "ascend_support": false,
        "cann_version": "N/A"
      },
      "migration": {
        "effort_level": "无需迁移",
        "blockers": [],
        "code_changes_required": []
      },
      "recommendation": "Memary核心不依赖GPU/CUDA，通过API调用外部LLM（OpenAI/Ollama），无需NPU适配。若使用本地Ollama推理模型，Ollama本身需要NPU适配，但这不属于Memary项目范围。"
    },
    "external_services": {
      "llm": {
        "providers": [
          "Ollama (Llama3, LLaVA)",
          "OpenAI (gpt-3.5-turbo, gpt-4-vision)",
          "Perplexity (mistral-7b-instruct)"
        ],
        "embedding_models": [
          "OpenAI text-embedding (通过llama-index)",
          "Ollama原生嵌入"
        ],
        "local_model_support": true,
        "cost_optimization": [
          "使用Ollama本地模型可降低70-80%成本",
          "混合方案：本地+云端降级"
        ]
      }
    },
    "deployment_detail": {
      "complexity": 6,
      "docker": {
        "available": false,
        "image_size": "N/A（无Dockerfile）",
        "multi_stage_build": false
      },
      "kubernetes": {
        "required": false,
        "recommended": true,
        "helm_available": false
      },
      "configuration": {
        "env_vars_count": 6,
        "secrets_count": 5,
        "complexity_level": "中等"
      },
      "observability": {
        "metrics_export": false,
        "structured_logging": false,
        "health_checks": false
      }
    }
  },
  "categories": {
    "tech_approach": [
      "Human Memory Simulation",
      "Knowledge Graph",
      "ReAct Framework"
    ],
    "use_case": [
      "Autonomous Agents",
      "Multi-agent Systems"
    ]
  },
  "innovations": {
    "key_features": [
      "双层记忆流架构（Memory Stream + Entity Knowledge Store）",
      "递归实体检索（最大深度2层）",
      "多跳推理（合并多个子图）",
      "同义词扩展检索",
      "零代码集成",
      "多图隔离（Multi-Graph，支持多代理）",
      "人类记忆仿真（宽度+深度两维度）",
      "自动记忆生成",
      "Context Window 管理与 Token 蒸馏"
    ],
    "improvements": [
      "基于 K-LaMP（Microsoft Research）设计的记忆模块",
      "改进的 KG RAG 检索器（递归+多跳）",
      "外部查询降级机制（Perplexity 集成）",
      "实体频率和时效性跟踪",
      "自动化记忆写回知识图谱",
      "支持本地模型（Ollama）零云成本部署",
      "Streamlit 可视化仪表板",
      "多模态支持（LLaVA 视觉工具）"
    ],
    "user_value": [
      "降低智能代理开发门槛（零代码集成）",
      "长期记忆能力增强对话连贯性",
      "个性化响应（基于用户知识深度）",
      "成本可控（支持完全本地部署）",
      "隐私保护（数据本地化选项）",
      "快速原型验证（Docker Compose 部署）",
      "多代理场景支持（FalkorDB 多图隔离）",
      "灵活扩展（从本地到企业级）"
    ]
  },
  "use_cases": {
    "scenarios": [
      "长期对话系统（客服机器人、个人助理）",
      "个人知识管理（笔记、日记、学习助手）",
      "专业知识库系统（医疗、法律、金融领域）",
      "多代理协作平台（团队记忆共享）",
      "教育领域（学习伴侣、智能辅导）",
      "游戏 NPC 记忆系统",
      "企业客户支持（上下文感知客服）",
      "研究助手（文献管理、知识图谱构建）"
    ],
    "companies": []
  },
  "value_propositions": [
    {
      "name": "人类记忆仿真架构",
      "description": "通过双层记忆流架构(Memory Stream + Entity Knowledge Store)和递归实体检索(最大深度2层),模拟人类记忆工作原理,实现多跳推理和同义词扩展检索,提供零代码集成的长期记忆能力。"
    },
    {
      "name": "多图隔离与本地部署",
      "description": "采用FalkorDB多图隔离技术支持多代理场景,结合Ollama本地模型实现零云成本部署,通过Context Window管理和Token蒸馏机制降低智能代理开发门槛,保障隐私数据本地化。"
    }
  ],
  "huawei_cloud": {
    "overall_difficulty": "中等",
    "recommended_services": {
      "database": {
        "primary": "华为云GaussDB(for Neo4j)或自建FalkorDB on ECS",
        "vector_solution": "无需（若未来需要可用CSS/Elasticsearch向量插件）"
      },
      "cache": "华为云DCS Redis（建议添加）",
      "compute": {
        "primary": "华为云ECS c7.2xlarge (8vCPU/16GB)",
        "ai_acceleration": "无需GPU/NPU"
      },
      "middleware": {
        "api_gateway": "华为云APIG",
        "load_balancer": "华为云ELB"
      }
    },
    "cost_estimation": {
      "small_scale": {
        "description": "1000活跃用户，FalkorDB自托管+Ollama本地",
        "monthly_cost": "¥500-800",
        "breakdown": {
          "ECS_app": "¥200（c7.large）",
          "ECS_graph_db": "¥200（c7.large，自建FalkorDB）",
          "EVS_storage": "¥50（100GB SSD）",
          "EIP_bandwidth": "¥50",
          "OBS_backup": "¥5"
        }
      },
      "medium_scale": {
        "description": "10000用户，Neo4j企业版+Ollama GPU推理",
        "monthly_cost": "¥8,000-15,000",
        "breakdown": {
          "ECS_app": "¥1,500（c7.2xlarge x2）",
          "ECS_neo4j_cluster": "¥4,500（c7.2xlarge x3）",
          "ECS_ollama_gpu": "¥2,000（GPU实例，若使用NPU可选Ai1s）",
          "EVS_storage": "¥500（1TB SSD）",
          "DCS_Redis": "¥300",
          "EIP_bandwidth": "¥200",
          "OBS_backup": "¥50"
        }
      }
    },
    "special_requirements": [
      "Neo4j在华为云无托管服务，需自建或使用GaussDB替代",
      "FalkorDB需要在ECS上自建容器化部署",
      "Ollama本地部署需要GPU/NPU实例（若选择本地推理）"
    ],
    "architecture_recommendations": [
      "使用华为云CCE(Kubernetes)部署图数据库集群，实现高可用",
      "LLM推理优先使用华为云ModelArts在线推理服务替代Ollama",
      "使用OBS存储JSON备份数据，降低存储成本",
      "通过APIG网关统一管理API访问，配合WAF保护"
    ]
  }
}