{
  "name": "locomo",
  "repository_url": "https://github.com/snap-research/locomo",
  "stars": 539,
  "primary_language": "Python",
  "description": "用于评估LLM代理超长期对话记忆的数据和代码（ACL 2024，SNAP Research）",
  "last_updated": "2024",
  "paper": {
    "exists": true,
    "title": "LoCoMo: Long-term Conversational Memory Benchmark",
    "venue": "ACL",
    "year": 2024,
    "url": "https://arxiv.org/abs/2402.17753"
  },
  "benchmarks": {
    "locomo": {
      "score": 0,
      "details": "This IS the LoCoMo benchmark - official SNAP Research implementation"
    }
  },
  "tech_stack": {
    "storage": [
      "Evaluation Dataset",
      "RAG Database"
    ],
    "frameworks": [
      "Python",
      "GPT-3.5-turbo"
    ],
    "languages": [
      "Python"
    ],
    "embedding_models": [
      "RAG support"
    ]
  },
  "cloud_needs": {
    "storage": {
      "types": [
        "Dataset Storage",
        "RAG DB"
      ],
      "requirements": [
        "10 conversations",
        "Multi-hop reasoning"
      ]
    },
    "compute": {
      "embedding": true,
      "gpu_needed": false,
      "estimated_requirements": "4-8 vCPUs for evaluation"
    },
    "deployment": {
      "complexity": 5,
      "containerized": true,
      "orchestration": [
        "Docker",
        "Research tools"
      ]
    },
    "storage_detail": {
      "vector_storage": {
        "solution": "pickle文件向量索引 (内存检索)",
        "database": "无外部向量DB (内存加载pickle)",
        "vector_dimension": 768,
        "index_type": "线性扫描 (torch cosine similarity)",
        "evidence": "task_eval/rag_utils.py: 使用torch计算向量相似度, device=cuda:0; 支持Contriever(768维)/Dragon(768维)/OpenAI(1536维); 向量以pickle格式存储"
      },
      "primary_database": {
        "type": "JSON文件存储",
        "min_version": "不适用",
        "required_extensions": [],
        "connection_pooling": {},
        "evidence": "data/locomo10.json(~2.8MB)为核心数据集; msc_personas_all.json为角色数据; 无任何数据库依赖"
      },
      "graph_database": {
        "required": false,
        "type": "无",
        "evidence": "事件图(因果关系)存储在JSON中,不使用外部图数据库; event_utils.py处理事件图但以JSON格式"
      },
      "cache": {
        "type": "无",
        "min_version": "不适用",
        "required_modules": [],
        "evidence": "无缓存机制"
      },
      "data_scale": {
        "estimated_total": "数据集~6MB; 评估结果~50MB; 模型权重10-140GB(可选本地模型)",
        "per_user_avg": "不适用(研究基准测试)",
        "evidence": "locomo10.json: 10个对话~2.8MB; msc_personas_all.json: ~3MB; 10个对话*20会话*15轮=3000个向量"
      },
      "performance": {
        "vector_search_latency": "1-10ms (内存检索, GPU加速)",
        "qps_target": "不适用(批处理评估)",
        "p95_latency": "不适用",
        "concurrent_connections": "不适用"
      }
    },
    "compute_detail": {
      "cpu": {
        "min_vcpu": 4,
        "recommended_vcpu": 8,
        "workload_type": "混合(GPU可选推理+API调用+评估计算)"
      },
      "memory": {
        "min_gb": 8,
        "recommended_gb": 16,
        "memory_intensive_ops": [
          "本地检索模型加载(Contriever~440MB)",
          "BLIP图像描述模型",
          "BERT-Score评估"
        ],
        "oom_risk": "中-使用大型本地模型时需要更多内存"
      },
      "gpu": {
        "required": false,
        "recommended": true,
        "use_case": "仅推理",
        "cuda_dependency": {
          "has_direct_cuda": true,
          "custom_cuda_kernels": false,
          "gpu_libraries": [
            "torch (PyTorch 2.0.1)",
            "torchvision",
            "sentence-transformers",
            "transformers",
            "xformers",
            "BLIP模型"
          ],
          "evidence": "requirements.txt(conda环境): pytorch=2.0.1 cuda11.7, xformers=0.0.22.post7; task_eval/rag_utils.py: torch.cuda.is_available(), device='cuda:0'; generative_agents/generate_conversations.py: BlipForConditionalGeneration.to('cuda')"
        }
      },
      "scalability": {
        "horizontal_scaling": false,
        "stateless": true,
        "auto_scaling_metrics": []
      },
      "serverless": {
        "suitable": false,
        "cold_start_tolerance": "不可接受",
        "reasons": [
          "模型加载时间长",
          "批处理评估任务",
          "GPU需求(本地模型)"
        ]
      },
      "concurrency": {
        "model": "单进程顺序执行",
        "async_framework": "无(同步脚本)",
        "message_queue": {
          "required": false,
          "systems": []
        },
        "websocket": false,
        "streaming": false
      }
    },
    "ascend_npu": {
      "compatibility_level": "需要工作量",
      "framework_analysis": {
        "framework": "PyTorch 2.0.1",
        "framework_version": "2.0.1 + CUDA 11.7",
        "ascend_support": true,
        "cann_version": "CANN 7.0+ (PyTorch 2.0适配)"
      },
      "migration": {
        "effort_level": "中等工作量",
        "blockers": [
          "xformers仅支持CUDA(但仅用于对话生成的diffusers,非核心功能)",
          "PyTorch CUDA 11.7版本需更新为昇腾兼容版本",
          "BLIP图像描述模型需要测试昇腾兼容性"
        ],
        "code_changes_required": [
          "task_eval/rag_utils.py: 将device='cuda:0'改为动态设备检测(torch_npu或cuda)",
          "generative_agents/generate_conversations.py: 将.to('cuda')改为动态设备",
          "移除xformers依赖(仅对话生成功能需要,评估功能不需要)",
          "更新PyTorch版本为昇腾兼容版本(torch_npu)",
          "BLIP模型可保持torch接口,通过torch_npu插件适配"
        ]
      },
      "recommendation": "该项目的GPU使用相对简单: 主要是标准PyTorch模型推理(Contriever/BLIP/sentence-transformers)和tensor运算。无自定义CUDA内核。迁移步骤: 1) 安装torch_npu替代CUDA版PyTorch; 2) 修改2个文件中的设备硬编码为动态检测; 3) 移除xformers(非核心); 4) 如仅使用API模型(GPT/Claude/Gemini)则完全不需要GPU,只有本地模型和RAG检索需要。"
    },
    "external_services": {
      "llm": {
        "providers": [
          "OpenAI GPT-3.5-turbo/GPT-4-turbo (对话生成+评估)",
          "Anthropic Claude (claude-sonnet/haiku)",
          "Google Gemini (gemini-pro-1.0)",
          "HuggingFace本地模型 (Gemma/LLaMA/Mistral)"
        ],
        "embedding_models": [
          "Contriever (Facebook, 768维)",
          "Dragon (768维)",
          "DPR",
          "OpenAI text-embedding-ada-002 (1536维)"
        ],
        "local_model_support": true,
        "cost_optimization": [
          "使用GPT-3.5-turbo而非GPT-4降低成本",
          "本地开源模型零API费用",
          "选择性评估(每种类型采样)"
        ]
      },
      "object_storage": {
        "providers": [
          "AWS S3",
          "Google Cloud Storage",
          "Azure Blob Storage",
          "阿里云OSS"
        ],
        "use_cases": [
          "基准数据集: locomo10.json (~2.8MB), msc_personas_all.json (~3MB)",
          "检索模型权重: Contriever (~440MB), Dragon (~1GB), DPR (~500MB)",
          "本地LLM模型: Gemma/LLaMA (10-140GB)",
          "BLIP图像描述模型 (~1GB)",
          "评估结果和向量embeddings (pickle格式, 50MB)",
          "生成的对话历史和图片"
        ],
        "estimated_storage": "数据集6MB + 检索模型2GB + LLM模型10-140GB + BLIP 1GB + 结果50MB = 13-143GB",
        "required": true,
        "cost_per_month": {
          "minimal": "$0.30 (数据集+结果, 仅API模式)",
          "with_retrieval": "$0.50 (含检索模型)",
          "with_local_llm": "$3-4 (含大型LLM模型)"
        }
      }
    },
    "deployment_detail": {
      "complexity": 5,
      "docker": {
        "available": false,
        "image_size": "~8GB (含CUDA运行时+PyTorch+模型依赖)",
        "multi_stage_build": false
      },
      "kubernetes": {
        "required": false,
        "recommended": false,
        "helm_available": false
      },
      "configuration": {
        "env_vars_count": 4,
        "secrets_count": 3,
        "complexity_level": "中等(需配置多个LLM API密钥+可选GPU环境)"
      },
      "observability": {
        "metrics_export": false,
        "structured_logging": false,
        "health_checks": false
      }
    }
  },
  "categories": {
    "tech_approach": [
      "Benchmark",
      "ACL 2024",
      "Official"
    ],
    "use_case": [
      "Memory Evaluation",
      "Conversational AI"
    ]
  },
  "innovations": [
    "首个超长期对话记忆评估基准，时间跨度达 240 天",
    "多任务评估框架：问答（5种类型）、事件摘要、多模态对话生成",
    "LLM驱动的对话生成框架，包含因果事件图和时序依赖",
    "分层记忆机制：粗粒度会话摘要 + 细粒度检索增强",
    "多模型多模态支持：GPT/Claude/Gemini + BLIP图像理解",
    "RAG多数据库模式：dialog/observation/summary三种检索策略",
    "标准化评估指标：F1/EM/Recall/BERT-Score多维度评估",
    "记忆反思机制：模拟长期关系中的洞察积累",
    "多跳推理能力测试：跨会话跨时间的复杂问答",
    "开源完整工具链：从数据生成到评估的端到端流程"
  ],
  "use_cases": [
    "长期个人助手：跨月度的用户关系管理和偏好记忆",
    "虚拟客服系统：历史对话追溯和上下文延续",
    "教育AI导师：学生学习历程追踪和个性化辅导",
    "健康管理助手：长期健康对话记录和趋势分析",
    "社交聊天机器人：模拟长期友谊和情感连接",
    "企业知识助手：跨时间的项目讨论和决策追踪",
    "心理咨询AI：长期治疗过程中的情绪和事件记录",
    "老年陪伴机器人：长期记忆衰退辅助和情感支持",
    "学术研究工具：评估新型记忆机制和检索策略",
    "记忆模型基准测试：对比不同LLM的长期记忆能力"
  ],
  "value_propositions": [
    {
      "name": "超长期对话记忆基准",
      "description": "首个超长期对话记忆评估基准(时间跨度达240天),通过多任务评估框架(问答5种类型、事件摘要、多模态对话生成)和LLM驱动的对话生成框架(因果事件图和时序依赖),提供标准化评估指标(F1/EM/Recall/BERT-Score多维度)(ACL 2024, SNAP Research)。"
    },
    {
      "name": "分层记忆与多跳推理",
      "description": "采用分层记忆机制(粗粒度会话摘要+细粒度检索增强)和RAG多数据库模式(dialog/observation/summary三种检索策略),支持多模型多模态(GPT/Claude/Gemini+BLIP图像理解)和记忆反思机制,实现跨会话跨时间的复杂问答和多跳推理能力测试。"
    }
  ],
  "huawei_cloud": {
    "overall_difficulty": "中等",
    "recommended_services": {
      "database": {
        "primary": "华为云OBS (JSON数据集+评估结果)",
        "vector_solution": "内存检索(无需外部向量DB)"
      },
      "cache": "不需要",
      "compute": {
        "primary": "华为云ECS (CPU实例用于API模型) 或 GPU实例 (本地模型推理)",
        "ai_acceleration": "华为云昇腾910B (标准PyTorch推理,需适配) 或 ModelArts在线推理"
      },
      "middleware": {}
    },
    "cost_estimation": {
      "small_scale": {
        "description": "纯API模式评估(GPT/Claude)",
        "monthly_cost": "¥1,000-3,000",
        "breakdown": {
          "compute_ecs": "¥200 (4vCPU/8GB CPU实例)",
          "openai_api": "¥500-2,000 (GPT-3.5-turbo)",
          "anthropic_api": "¥200-500 (Claude)",
          "storage_obs": "¥10"
        }
      },
      "medium_scale": {
        "description": "本地模型+API混合评估",
        "monthly_cost": "¥5,000-10,000",
        "breakdown": {
          "gpu_ecs": "¥3,000 (昇腾910B 或 V100, 100小时)",
          "cpu_ecs": "¥200",
          "llm_api": "¥1,000-5,000",
          "storage_obs": "¥50",
          "network": "¥200"
        }
      }
    },
    "special_requirements": [
      "PyTorch 2.0.1需适配昇腾NPU版本(torch_npu)",
      "仅2个Python文件需要修改GPU设备硬编码",
      "xformers库需移除(昇腾不支持,但非核心功能)",
      "BLIP图像描述模型需测试昇腾兼容性",
      "如仅使用API模型(GPT/Claude/Gemini)则完全不需要GPU"
    ],
    "architecture_recommendations": [
      "推荐分两种模式: 纯API模式(零GPU需求)和混合模式(本地模型+API)",
      "纯API模式: 使用ECS CPU实例即可,成本最低",
      "混合模式: 使用华为云ModelArts部署Contriever等检索模型",
      "评估结果存储到华为云OBS,方便长期归档和分析",
      "可考虑使用华为盘古大模型API替代OpenAI/Claude以减少跨境网络延迟",
      "BLIP图像描述功能可通过华为云ModelArts的图像理解API替代"
    ]
  }
}