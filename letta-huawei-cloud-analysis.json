{
  "project_name": "letta",
  "analysis_date": "2026-02-13",
  "version_analyzed": "v0.16.4",

  "storage": {
    "vector_storage": {
      "solution": "Native PGVector或Pinecone或Turbopuffer",
      "default_database": "PGVector (PostgreSQL扩展)",
      "recommended_for_huawei": "PostgreSQL+pgvector (RDS) 或 自建Qdrant",
      "vector_dimension": 1536,
      "vector_dimension_notes": "默认1536维(OpenAI text-embedding-3-small), 可配置为1024维(Letta默认), 最大支持4096维",
      "index_type": "pgvector HNSW或IVFFlat",
      "index_type_notes": "pgvector支持HNSW和IVFFlat索引, Archival Memory使用向量搜索实现长期记忆检索",
      "supported_databases": [
        "PGVector (默认, PostgreSQL扩展)",
        "Pinecone (托管SaaS)",
        "Turbopuffer (托管SaaS)",
        "Qdrant (自建推荐)",
        "Chroma (开发测试)",
        "FAISS (本地)",
        "Weaviate (自建)"
      ],
      "evidence": "从pyproject.toml第88-96行确认支持pgvector>=0.2.3, pinecone[asyncio]>=7.3.0, turbopuffer>=0.5.17; schemas/enums.py第265-271行定义VectorDBProvider枚举(NATIVE/TPUF/PINECONE); constants.py第91行MAX_EMBEDDING_DIM=4096, 第93行DEFAULT_EMBEDDING_DIM=1024; schemas/passage.py第44-75行实现向量padding到MAX_EMBEDDING_DIM"
    },

    "primary_database": {
      "type": "PostgreSQL或SQLite",
      "min_version": "PostgreSQL 12+ (推荐14+), SQLite 3.35+",
      "recommended_version": "PostgreSQL 14或15",
      "required_extensions": ["pgvector>=0.2.3 (用于向量存储)", "asyncpg>=0.30.0 (异步驱动)", "pg8000>=1.30.3 (同步驱动)"],
      "connection_pooling": {
        "min_connections": 25,
        "max_overflow": 10,
        "pool_timeout": 30,
        "pool_recycle": 1800,
        "configurable": true
      },
      "ssl_support": true,
      "evidence": "settings.py第273-287行显示PostgreSQL连接池配置pg_pool_size=25, pg_max_overflow=10, pg_pool_timeout=30, pg_pool_recycle=1800; pyproject.toml第88-93行显示postgres依赖pgvector>=0.2.3, asyncpg>=0.30.0, pg8000>=1.30.3, psycopg2-binary>=2.9.10; database_utils.py第97-143行实现asyncpg和pg8000驱动转换, 支持SSL; Dockerfile第2行使用ankane/pgvector:v0.5.1作为基础镜像"
    },

    "graph_database": {
      "required": false,
      "recommended": false,
      "notes": "Letta不使用图数据库, 与Mem0的三层架构(向量+图+历史)不同, Letta采用三层内存架构(Core Memory/Recall Memory/Archival Memory), 均存储在PostgreSQL中"
    },

    "cache": {
      "type": "Redis",
      "required": false,
      "min_version": "6.2.0",
      "use_case": "可选, 用于会话状态、embedding缓存、消息队列",
      "required_modules": [],
      "alternatives": [],
      "evidence": "pyproject.toml第94行显示redis依赖redis>=6.2.0; settings.py第289-290行显示Redis配置redis_host和redis_port=6379; Dockerfile第60行安装redis-server; compose.yaml未配置Redis服务(可选组件)"
    },

    "object_storage": {
      "required": false,
      "use_case": "Agent附件、文件存储、数据备份、日志归档",
      "supported": ["AWS S3", "阿里云OSS", "S3-compatible (MinIO)"],
      "evidence": "pyproject.toml第111-113行显示bedrock依赖boto3>=1.36.24用于AWS集成; cloud-needs.md第140-198行详细描述对象存储需求, 支持S3及兼容协议"
    },

    "data_scale": {
      "estimated_total": "PostgreSQL主数据约5-50GB(100万消息), 向量数据6-60GB(100万passages), 无图数据库",
      "per_agent_avg": "每个Agent约10MB元数据 + 5GB消息历史(10000条) + 6MB向量数据(1000个passages)",
      "storage_breakdown": {
        "agent_metadata": "约10KB/agent (Agent状态、配置、工具)",
        "message_history": "约500字节/message (Recall Memory消息表)",
        "archival_passages": "约6KB/passage (1536维float32向量 + text + metadata)",
        "core_memory": "约8KB/agent (Core Memory Blocks, 存储在Agent表中)",
        "vector_index_overhead": "2-3倍原始数据大小(HNSW索引)",
        "user_and_org": "约100MB (用户、组织、工具、提示词管理)"
      },
      "evidence": "基于schemas/passage.py向量维度1536*4字节=6144字节; constants.py第76-77行MIN_CONTEXT_WINDOW=4096, DEFAULT_CONTEXT_WINDOW=32000; architecture.md描述三层内存架构; cloud-needs.md第334-397行详细估算存储容量"
    }
  },

  "compute": {
    "cpu": {
      "min_vcpu": 2,
      "recommended_vcpu": 4,
      "optimal_vcpu": "8-16 (中型生产)",
      "workload_type": "IO密集型和CPU密集型混合",
      "workload_notes": "FastAPI异步处理请求, LLM API调用为IO密集型, 本地embedding生成为CPU密集型, Agent消息循环需要较高CPU"
    },

    "memory": {
      "min_gb": 4,
      "recommended_gb": 8,
      "optimal_gb": "16-32 (中型生产)",
      "memory_intensive_ops": [
        "Agent状态缓存(多个并发Agent)",
        "向量索引加载(HNSW索引常驻内存)",
        "消息历史缓冲(Recall Memory)",
        "FastAPI应用内存占用",
        "LLM响应流式处理"
      ]
    },

    "gpu": {
      "required": false,
      "use_case": "仅在自托管LLM推理或embedding时需要GPU, 使用外部API则无需GPU",
      "optional_scenarios": "1) 自托管vLLM推理(Llama等开源模型) 2) 自托管embedding模型 3) 使用外部API(OpenAI/Anthropic)则无需GPU",
      "cuda_dependency": {
        "has_direct_cuda": false,
        "custom_cuda_kernels": false,
        "gpu_libraries": [
          "vllm (可选, 用于自托管LLM推理, 需要CUDA GPU)",
          "llama-index-embeddings-openai (可选, 用于embedding, 默认使用API无需GPU)"
        ],
        "evidence": "docker-compose-vllm.yaml第16-36行配置vLLM服务, 使用runtime: nvidia和GPU资源; pyproject.toml第43-44行llama-index>=0.12.2, llama-index-embeddings-openai>=0.3.1为可选依赖; .github/workflows/test-vllm.yml测试vLLM集成; 核心代码无直接CUDA调用, GPU仅用于可选的自托管推理"
      },
      "gpu_models": [
        {
          "use_case": "自托管LLM推理(vLLM)",
          "model": "Llama 3.3 70B / Qwen 2.5 72B / Mistral 8x22B",
          "vram": "80GB (A100) × 4 或 40GB (A40) × 8",
          "throughput": "50-100 tokens/秒"
        },
        {
          "use_case": "自托管embedding",
          "model": "sentence-transformers/all-MiniLM-L6-v2",
          "vram": "2-4GB (T4即可)",
          "throughput": "500-1000 embeddings/秒"
        }
      ]
    },

    "ascend_npu": {
      "compatibility_level": "容易适配",
      "overall_assessment": "Letta核心功能完全不依赖GPU。可选的自托管LLM推理(vLLM)和embedding生成可通过昇腾CANN适配，但推荐使用外部API降低部署复杂度。",

      "framework_analysis": {
        "framework": "无强制深度学习框架依赖",
        "framework_version": "可选vLLM(依赖PyTorch), 可选llama-index(依赖transformers)",
        "framework_usage": "可选(仅自托管LLM或embedding时)",
        "ascend_support": true,
        "cann_version": "CANN 8.0 RC1+",
        "pytorch_ascend_version": "torch_npu 2.1.0+ (仅自托管场景)",
        "evidence": "pyproject.toml核心依赖不包含torch/tensorflow; docker-compose-vllm.yaml第16-36行显示vLLM为可选部署方式; constants.py第23行vllm在PROVIDER_ORDER中排第9位, 为非默认选项; 默认使用外部LLM API(OpenAI/Anthropic/Google等20+提供商)"
      },

      "migration": {
        "effort_level": "低",
        "migration_path": "推荐方案: 使用外部API(无需迁移) | 备选方案: 自托管需适配vLLM到昇腾",
        "blockers": [],
        "code_changes_required": [
          "若自托管LLM: 使用昇腾版vLLM或MindIE推理引擎替代NVIDIA vLLM",
          "若自托管embedding: 安装torch-npu, 修改device='cuda'为device='npu'",
          "可选: 使用华为云ModelArts托管推理服务(无需自行适配)"
        ],
        "testing_required": [
          "验证昇腾vLLM/MindIE推理精度和性能",
          "压测并发Agent场景下的吞吐量",
          "测试长上下文(128K+ tokens)推理稳定性"
        ]
      },

      "deployment_scenarios": [
        {
          "scenario": "推荐方案1: 使用外部LLM API",
          "description": "使用OpenAI/Anthropic/Google等20+提供商的API, Letta完全支持模型无关架构",
          "npu_required": false,
          "difficulty": "无",
          "cost": "按API调用付费(GPT-4.1-mini约¥2/百万tokens)",
          "华为云支持": "支持通过公网调用外部API, 或使用华为云Pangu模型API"
        },
        {
          "scenario": "推荐方案2: 华为云ModelArts托管推理",
          "description": "使用华为云ModelArts部署开源模型(Llama/Qwen等), 通过API调用",
          "npu_required": false,
          "difficulty": "低(需配置ModelArts endpoint到Letta)",
          "cost": "按推理时长付费(昇腾NPU实例¥2-8/小时)",
          "华为云支持": "原生支持, 基于昇腾910B NPU"
        },
        {
          "scenario": "方案3: 自托管vLLM on 昇腾NPU",
          "description": "在华为云ECS昇腾NPU实例上自托管vLLM推理引擎",
          "npu_required": true,
          "difficulty": "中(需使用昇腾版vLLM或MindIE引擎)",
          "cost": "固定实例费用(昇腾910B实例¥5000-15000/月, 视规模)",
          "华为云支持": "支持, 提供ECS ai1s系列实例(昇腾310/910)"
        }
      ],

      "recommendation": "对于Letta项目, 强烈推荐使用外部API或华为云ModelArts托管推理, 无需昇腾NPU适配。仅当月LLM API成本超过¥30,000且需私有化部署时, 再考虑昇腾NPU自托管方案。代码适配工作量极小(主要是配置endpoint), 预计1-2天。"
    },

    "serverless": {
      "suitable": false,
      "reasons": [
        "Agent需要维护长期状态和会话连续性(Core Memory持久化)",
        "PostgreSQL需要持久连接池(25-35并发连接)",
        "向量索引(HNSW)需要预加载到内存(冷启动慢)",
        "长时间运行的Agent消息循环(非事件驱动)",
        "需要WebSocket支持实时流式响应"
      ],
      "partial_serverless": {
        "feasible": true,
        "approach": "API层使用云容器实例(CCI)常驻, 后台Worker使用Serverless Jobs(定时任务), 数据层使用托管服务(RDS+Redis)",
        "limitations": "至少需要1-2个常驻实例维护Agent状态缓存和连接池"
      }
    }
  },

  "external_services": {
    "llm": {
      "providers": [
        "OpenAI (gpt-4, gpt-4.1, gpt-4.1-mini, gpt-4o)",
        "Anthropic (claude-4.5-sonnet, claude-4.5-opus, claude-4.5-haiku)",
        "Google (gemini-2.5-pro, gemini-2.5-flash)",
        "Groq (llama-3.3-70b, mixtral-8x7b)",
        "Azure OpenAI",
        "Bedrock (AWS)",
        "Ollama (自托管)",
        "vLLM (自托管)",
        "Together AI",
        "DeepSeek",
        "xAI (Grok)",
        "Mistral AI",
        "Minimax",
        "LM Studio",
        "ZhipuAI",
        "OpenRouter",
        "Letta托管模型"
      ],
      "default_model": "无强制默认(模型无关架构)",
      "cost_per_million_tokens": "GPT-4.1-mini: $0.15输入+$0.60输出, Claude Haiku: $0.25输入+$1.25输出, Gemini Flash: $0.075输入+$0.30输出",
      "monthly_cost_estimate": "¥3,000-10,000 (1000个Agent, 每Agent每月1000条消息)",
      "evidence": "settings.py第109-214行配置20+LLM提供商API密钥; constants.py第12-29行PROVIDER_ORDER列出所有支持的提供商; model_specs/model_prices_and_context_window.json(31925行)包含完整模型定价和能力; cloud-needs.md第662-764行详细分析LLM成本估算"
    },

    "embedding_models": {
      "providers": [
        "OpenAI (text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002)",
        "Anthropic",
        "Bedrock",
        "Google AI",
        "Google Vertex",
        "Azure OpenAI",
        "Groq",
        "Ollama",
        "vLLM",
        "HuggingFace",
        "Mistral",
        "Together",
        "Pinecone (llama-text-embed-v2)",
        "Letta托管embedding"
      ],
      "default_model": "text-embedding-3-small或letta-free",
      "default_dimensions": 1536,
      "cost_per_million_tokens": "$0.02 (OpenAI text-embedding-3-small)",
      "monthly_cost_estimate": "¥100-500 (100万passages embedding生成)",
      "evidence": "schemas/embedding_config.py第8-89行定义EmbeddingConfig, 支持20+endpoint类型; constants.py第91-99行定义embedding维度和tokenizer映射; pyproject.toml第43-44行llama-index-embeddings-openai用于embedding; cloud-needs.md第79-136行详细描述embedding方案对比"
    }
  },

  "deployment": {
    "containerization": {
      "supported": true,
      "dockerfile": "Dockerfile (基于ankane/pgvector:v0.5.1)",
      "base_image": "ankane/pgvector:v0.5.1 (包含PostgreSQL+pgvector+Python3.11)",
      "multi_stage": true,
      "image_size": "约2-3GB(包含所有依赖)"
    },

    "orchestration": {
      "kubernetes": true,
      "docker_compose": true,
      "compose_files": ["compose.yaml (生产)", "dev-compose.yaml (开发)", "docker-compose-vllm.yaml (自托管LLM)"]
    },

    "cloud_native": {
      "health_checks": true,
      "graceful_shutdown": true,
      "horizontal_scaling": true,
      "observability": "OpenTelemetry集成(Datadog/ClickHouse/SigNoz)"
    }
  },

  "huawei_cloud": {
    "overall_difficulty": "低",
    "difficulty_notes": "Letta架构简单(仅PostgreSQL+可选Redis), 无需图数据库, 华为云完全支持。主要挑战在于自托管LLM时的昇腾NPU适配, 但推荐使用外部API规避此问题。",

    "recommended_services": {
      "database": {
        "service": "RDS for PostgreSQL",
        "version": "PostgreSQL 14.8或15.3",
        "instance_type": "高可用版(主备)",
        "spec": "通用型 | 2核8GB(小规模) 到 8核32GB(中规模)",
        "storage": "云盘SSD 100-500GB",
        "extensions": ["pgvector 0.5.1 (需手动安装或联系华为云技术支持)"],
        "notes": "pgvector扩展需确认华为云RDS版本支持, 建议提前咨询技术支持"
      },

      "vector_solution": {
        "option1": "RDS PostgreSQL + pgvector扩展",
        "option1_version": "PostgreSQL 14或15",
        "option1_instance": "RDS for PostgreSQL 高可用版",
        "option1_spec": "通用型 | 4核16GB起步",
        "option1_storage": "云盘SSD 200GB起",
        "option2": "自建Qdrant on ECS",
        "option2_instance": "通用计算增强型 s7.xlarge.4",
        "option2_spec": "4核16GB",
        "option2_storage": "高IO云盘 200GB",
        "recommendation": "推荐RDS+pgvector(运维简单), 除非向量规模超过500万条才考虑自建Qdrant"
      },

      "cache": {
        "service": "DCS for Redis",
        "version": "Redis 6.0或7.0",
        "instance_type": "主备版",
        "spec": "2GB-8GB内存",
        "use_case": "可选(用于会话缓存、embedding缓存)"
      },

      "compute": {
        "service": "CCE (云容器引擎) 或 ECS",
        "recommended": "CCE Kubernetes集群",
        "node_spec": "通用计算增强型 s7.xlarge.4 (4核16GB) × 3节点",
        "auto_scaling": "支持HPA(水平扩缩容)",
        "alternative": "云容器实例CCI(无服务器容器, 不推荐因需常驻实例)"
      },

      "llm_inference": {
        "scenario": "核心推荐方案",
        "option1": "外部LLM API(OpenAI/Anthropic/Google)",
        "option1_cost": "按调用付费(GPT-4.1-mini约¥2/百万tokens)",
        "option1_difficulty": "无(直接配置API Key)",
        "option2": "华为云ModelArts托管推理",
        "option2_cost": "昇腾NPU实例¥2-8/小时",
        "option2_difficulty": "低(需配置endpoint)",
        "option3": "自托管vLLM on 昇腾NPU",
        "option3_cost": "ECS ai1s实例¥5000-15000/月",
        "option3_difficulty": "中(需适配vLLM或使用MindIE)",
        "recommendation": "强烈推荐option1或option2, 除非月API成本超过¥30,000且需私有化"
      },

      "load_balancer": {
        "service": "ELB (弹性负载均衡)",
        "type": "应用型负载均衡(HTTP/HTTPS)",
        "bandwidth": "5Mbps起(按需扩容)"
      },

      "monitoring": {
        "service": "云监控CES + 应用性能管理APM",
        "metrics": "CPU、内存、网络、应用QPS、延迟、Agent并发数",
        "alerting": "支持短信/邮件/企业微信告警"
      },

      "object_storage": {
        "service": "OBS (对象存储服务)",
        "use_case": "Agent附件、文件存储、备份、日志归档",
        "storage_class": "标准存储(热数据) / 低频访问(冷数据)"
      }
    },

    "cost_estimation": {
      "small_scale": {
        "description": "100个Agent, 10,000条消息, 100 QPS",
        "monthly_cost": "¥1,800-2,800",
        "breakdown": {
          "RDS PostgreSQL": "¥600 (2核8GB 高可用版 + 100GB存储)",
          "CCE节点": "¥800 (s7.xlarge.4 4核16GB × 2节点)",
          "ELB": "¥80 (5Mbps带宽)",
          "外部LLM API": "¥300 (GPT-4.1-mini, 约5万条消息/月)",
          "监控和其他": "¥100"
        },
        "notes": "假设使用外部OpenAI API, 不自托管LLM, 无Redis缓存"
      },

      "medium_scale": {
        "description": "1000个Agent, 100,000条消息, 500 QPS",
        "monthly_cost": "¥5,000-7,500",
        "breakdown": {
          "RDS PostgreSQL": "¥1,800 (4核16GB 高可用版 + 300GB存储)",
          "CCE节点": "¥2,400 (s7.xlarge.4 4核16GB × 4节点)",
          "ELB": "¥150 (10Mbps带宽)",
          "DCS Redis": "¥250 (主备版 4GB)",
          "外部LLM API": "¥3,000 (GPT-4.1-mini, 约100万条消息/月)",
          "监控和其他": "¥200"
        },
        "notes": "使用外部API, 启用Redis缓存降低延迟"
      },

      "large_scale": {
        "description": "10,000个Agent, 1,000,000条消息, 2000 QPS",
        "monthly_cost": "¥15,000-25,000",
        "breakdown": {
          "RDS PostgreSQL": "¥4,500 (8核32GB 高可用版 + 1TB存储)",
          "CCE节点": "¥7,200 (s7.2xlarge.4 8核32GB × 6节点)",
          "ELB": "¥400 (50Mbps带宽)",
          "DCS Redis": "¥550 (主备版 8GB)",
          "自托管LLM (ModelArts)": "¥8,000 (昇腾NPU推理实例, 24x7运行)",
          "自托管Embedding": "¥1,500 (ECS GPU实例 pi2.xlarge.4)",
          "OBS备份": "¥100 (500GB存储)",
          "监控和其他": "¥500"
        },
        "notes": "此规模建议自托管LLM和Embedding降低API成本"
      },

      "cost_optimization_tips": [
        "使用包年包月享85折优惠",
        "非高峰时段可缩容CCE节点数量(通过CronHPA)",
        "LLM API成本优化: 1) 启用Prompt Caching(Anthropic降低90%成本) 2) 使用更小模型(GPT-4.1-mini) 3) 优化Recall Memory加载量",
        "向量数据量化压缩(Scalar Quantization)节省50%存储",
        "冷数据归档到OBS低频存储类",
        "自托管LLM盈亏平衡点: 月API成本超过¥30,000时考虑ModelArts或昇腾NPU实例",
        "使用华为云预留实例(RI)降低30%计算成本"
      ]
    },

    "special_requirements": [
      "pgvector扩展需要PostgreSQL 12+, 确认华为云RDS版本支持(推荐14或15)",
      "向量索引(HNSW)需要足够内存, RDS内存配置建议为数据量的2-3倍",
      "Agent并发需要合理的数据库连接池(pool_size=25, max_overflow=10)",
      "若使用昇腾NPU自托管LLM, 需确认vLLM或MindIE引擎的模型兼容性",
      "长上下文模型(128K+ tokens)需要更大内存的ECS实例",
      "WebSocket长连接支持(用于流式响应), 需配置ELB空闲超时时间"
    ],

    "architecture_recommendations": [
      {
        "scale": "小规模(< 1万消息/月)",
        "architecture": "单可用区 | RDS+CCE(2节点)",
        "diagram": "ELB → CCE(Letta API × 2) → RDS PostgreSQL (2核8GB 高可用版)",
        "cost": "¥1,800-2,800/月",
        "sla": "99.9%"
      },
      {
        "scale": "中规模(1-10万消息/月)",
        "architecture": "多可用区 | RDS主备+CCE集群+Redis",
        "diagram": "ELB → CCE(Letta API × 4 Auto-scaling) → RDS HA (4核16GB) + DCS Redis (4GB)",
        "cost": "¥5,000-7,500/月",
        "sla": "99.95%"
      },
      {
        "scale": "大规模(10万+消息/月)",
        "architecture": "多可用区 | RDS读写分离+CCE自动扩缩容+ModelArts推理",
        "diagram": "ELB → CCE(Auto-scaling 4-12节点) → RDS主备+只读副本 (8核32GB) + DCS Redis (8GB) + ModelArts(昇腾NPU推理)",
        "cost": "¥15,000-25,000/月",
        "sla": "99.99%",
        "notes": "此规模建议自托管LLM和Embedding, 使用华为云ModelArts或ECS昇腾NPU实例"
      }
    ],

    "deployment_steps": [
      {
        "step": 1,
        "title": "准备基础设施",
        "tasks": [
          "创建VPC和子网(至少2个可用区)",
          "配置安全组(开放80/443/5432端口)",
          "创建RDS PostgreSQL实例(14.8或15.3)",
          "安装pgvector扩展(联系华为云技术支持或参考文档手动安装)"
        ]
      },
      {
        "step": 2,
        "title": "配置数据库",
        "tasks": [
          "创建letta数据库和用户",
          "执行init.sql初始化脚本",
          "配置连接池参数(max_connections=100+)",
          "启用pgvector扩展: CREATE EXTENSION vector;",
          "创建HNSW向量索引"
        ]
      },
      {
        "step": 3,
        "title": "部署Letta应用",
        "tasks": [
          "创建CCE Kubernetes集群(3节点起)",
          "构建Letta Docker镜像(基于Dockerfile)",
          "创建ConfigMap(配置数据库连接、LLM API Key)",
          "创建Secret(存储敏感信息如OpenAI API Key)",
          "部署Deployment和Service资源",
          "配置HPA(水平Pod自动扩缩容)"
        ]
      },
      {
        "step": 4,
        "title": "配置负载均衡和域名",
        "tasks": [
          "创建ELB应用型负载均衡器",
          "绑定CCE Service",
          "配置健康检查(HTTP /health)",
          "申请SSL证书",
          "配置HTTPS监听器",
          "绑定域名(可选)"
        ]
      },
      {
        "step": 5,
        "title": "配置LLM推理(可选)",
        "tasks": [
          "选项1: 配置外部LLM API Key (OpenAI/Anthropic/Google)",
          "选项2: 创建ModelArts推理服务(部署Llama/Qwen等模型)",
          "选项3: 创建ECS昇腾NPU实例, 部署vLLM或MindIE引擎",
          "配置Letta连接到推理endpoint"
        ]
      },
      {
        "step": 6,
        "title": "监控和告警",
        "tasks": [
          "启用云监控CES",
          "配置自定义指标(QPS、延迟、错误率、Agent并发数)",
          "设置告警规则(CPU>80%, 内存>85%, 错误率>5%)",
          "集成APM应用性能管理(可选)",
          "配置日志采集到LTS日志服务"
        ]
      },
      {
        "step": 7,
        "title": "测试和优化",
        "tasks": [
          "功能测试(创建Agent、发送消息、检索Archival Memory)",
          "性能测试(压测100-1000 QPS)",
          "调优数据库连接池(pg_pool_size, pg_max_overflow)",
          "调优HNSW索引参数(m, ef_construction)",
          "验证备份恢复流程"
        ]
      }
    ],

    "migration_from_other_clouds": {
      "from_aws": {
        "mapping": {
          "RDS PostgreSQL": "直接迁移(使用DRS数据复制服务)",
          "ECS/EKS": "重新部署到CCE",
          "ElastiCache Redis": "迁移到DCS Redis",
          "S3": "迁移到OBS"
        },
        "challenges": [
          "pgvector扩展需确认华为云RDS版本兼容性",
          "自托管vLLM需适配昇腾NPU(或改用ModelArts)"
        ]
      },
      "from_gcp": {
        "mapping": {
          "Cloud SQL PostgreSQL": "使用DRS迁移到RDS",
          "GKE": "重新部署到CCE",
          "Memorystore Redis": "迁移到DCS Redis"
        }
      }
    },

    "华为云特有优势": [
      "国内网络延迟低(相比海外云服务)",
      "数据主权和合规性(满足网络安全法)",
      "技术支持响应快(中文服务)",
      "昇腾NPU可选(适合自托管大模型推理)",
      "与华为云Pangu大模型API深度集成"
    ],

    "华为云局限性": [
      "pgvector扩展需手动安装或联系技术支持(不如AWS RDS开箱即用)",
      "无托管向量数据库服务(需自建Qdrant或使用pgvector)",
      "昇腾NPU生态相比NVIDIA CUDA较弱(vLLM等工具需适配)",
      "海外区域覆盖不如AWS/GCP",
      "开源社区生态相比国际云厂商较弱"
    ]
  },

  "technical_details": {
    "programming_language": "Python 3.11-3.13",
    "web_framework": "FastAPI (异步)",
    "orm": "SQLAlchemy 2.0+ (异步模式)",
    "async_support": true,
    "containerized": true,
    "container_base_image": "ankane/pgvector:v0.5.1",
    "package_manager": "uv (pyproject.toml)",

    "dependencies_summary": {
      "core_required": [
        "fastapi>=0.115.6",
        "sqlalchemy[asyncio]>=2.0.41",
        "pydantic>=2.10.6",
        "openai>=2.11.0",
        "anthropic>=0.75.0",
        "llama-index>=0.12.2",
        "httpx>=0.28.0"
      ],
      "optional_databases": "postgres, redis, pinecone, sqlite",
      "optional_llm_providers": "20+ providers (OpenAI, Anthropic, Google, Groq, Ollama, vLLM等)",
      "optional_embedders": "OpenAI, Pinecone, HuggingFace, Ollama等"
    },

    "performance_characteristics": {
      "message_latency_p95": "< 2000ms (使用外部LLM API, 含LLM推理时间)",
      "archival_search_latency_p95": "< 100ms (HNSW索引向量检索)",
      "throughput_per_instance": "50-100 并发Agent (4核8GB)",
      "vector_index_load_time": "5-10秒 (10万向量)",
      "connection_pool_overhead": "每个DB连接约10MB内存"
    },

    "security_features": [
      "API Key认证(可扩展为OAuth2)",
      "Organization级别数据隔离(multi-tenant)",
      "SSL/TLS支持(PostgreSQL连接)",
      "敏感数据加密存储(Agent secrets)",
      "审计日志(所有Agent操作记录)",
      "RBAC权限控制(User/Organization/Agent)"
    ]
  },

  "deployment_complexity_assessment": {
    "overall_score": "5/10",
    "factors": {
      "service_count": "低(2-3个核心服务: PostgreSQL + Letta API + 可选Redis)",
      "state_management": "中(Agent状态持久化到PostgreSQL, Core/Recall/Archival三层内存)",
      "data_consistency": "低(单一PostgreSQL数据库, 无跨库事务)",
      "monitoring": "中(需监控Agent并发数、消息延迟、LLM API调用)",
      "scaling": "低(大部分组件支持水平扩展)"
    },
    "complexity_drivers": [
      "Agent长期状态管理和会话连续性",
      "LLM API调用需要处理限流、重试、超时",
      "向量检索性能调优(HNSW索引参数)",
      "自托管LLM时的GPU/NPU资源管理(可选)"
    ]
  },

  "recommendations": {
    "quick_start": {
      "phase": "原型验证(1-2周)",
      "approach": "本地Docker Compose + OpenAI API",
      "cost": "¥100-500 (仅API调用)"
    },
    "production_ready": {
      "phase": "生产部署(3-4周)",
      "approach": "华为云CCE + RDS PostgreSQL + OpenAI/Anthropic API",
      "cost": "¥1,800-7,500/月 (根据规模)"
    },
    "enterprise_scale": {
      "phase": "企业级(2-3月)",
      "approach": "多可用区HA + 读写分离 + ModelArts托管推理(可选昇腾NPU)",
      "cost": "¥15,000-25,000/月"
    },

    "best_practices": [
      "优先使用托管服务降低运维成本(RDS, DCS)",
      "配置合理的连接池大小(pg_pool_size=25, 避免数据库连接耗尽)",
      "启用LLM Prompt Caching降低90%重复提示词成本(Anthropic Claude)",
      "使用更小的LLM模型降低成本(GPT-4.1-mini比GPT-4便宜83%)",
      "定期清理过期消息和Archival Memory(如6个月以上)",
      "监控Agent并发数和消息延迟, 设置预算告警",
      "使用蓝绿部署或金丝雀发布降低上线风险",
      "备份PostgreSQL数据到OBS(每日增量+每周全量)"
    ],

    "cost_optimization_strategies": [
      "使用包年包月享85折优惠",
      "非高峰时段缩减CCE节点(通过CronHPA)",
      "LLM成本优化: 1) 启用Prompt Caching 2) 使用GPT-4.1-mini或Claude Haiku 3) 减少Recall Memory加载量",
      "自托管盈亏平衡点: 月LLM API成本超过¥30,000时考虑ModelArts或昇腾NPU",
      "使用华为云预留实例(RI)降低30%计算成本",
      "向量数据量化(Scalar Quantization)减少50%存储和内存占用",
      "冷数据归档到OBS低频存储类"
    ]
  },

  "risks_and_mitigations": {
    "technical_risks": [
      {
        "risk": "PostgreSQL单点故障",
        "impact": "高(所有Agent状态和消息历史不可用)",
        "mitigation": "使用RDS高可用版(主备自动切换) + 定期备份到OBS + 配置只读副本分担查询",
        "probability": "低"
      },
      {
        "risk": "向量索引损坏或性能下降",
        "impact": "中(Archival Memory检索失败或变慢)",
        "mitigation": "定期备份向量数据 + 配置HNSW索引自动重建 + 监控检索延迟",
        "probability": "低"
      },
      {
        "risk": "LLM API限流或故障",
        "impact": "高(Agent无法生成回复)",
        "mitigation": "配置多LLM提供商failover(OpenAI→Anthropic→Groq) + 实现指数退避重试 + 设置超时和熔断",
        "probability": "中"
      },
      {
        "risk": "Agent并发过高导致数据库连接耗尽",
        "impact": "高(新Agent无法创建连接)",
        "mitigation": "配置合理连接池(pool_size=25, max_overflow=10) + 监控连接使用率 + 配置HPA自动扩容",
        "probability": "中"
      },
      {
        "risk": "内存泄漏(Python应用)",
        "impact": "中(需定期重启Pod)",
        "mitigation": "配置Pod内存限制 + 定期重启策略 + 内存监控告警",
        "probability": "低"
      }
    ],
    "business_risks": [
      {
        "risk": "成本超预算",
        "impact": "中",
        "mitigation": "设置云账单告警 + 定期成本审查 + 优化LLM API调用频率 + 启用Prompt Caching",
        "probability": "中"
      },
      {
        "risk": "数据合规问题",
        "impact": "高(若涉及个人隐私数据)",
        "mitigation": "数据加密存储 + 定期安全审计 + 实现数据删除接口(GDPR) + 使用华为云数据主权",
        "probability": "低"
      }
    ]
  },

  "next_steps": [
    "1. 申请华为云账号并完成实名认证",
    "2. 在华为云控制台创建VPC和子网规划",
    "3. 部署RDS PostgreSQL实例并安装pgvector扩展(联系技术支持)",
    "4. 配置外部LLM API Key (OpenAI/Anthropic/Google) 或创建ModelArts推理服务",
    "5. 本地构建Letta Docker镜像并测试",
    "6. 创建CCE集群并部署Letta应用",
    "7. 配置ELB和域名",
    "8. 执行功能和性能测试(创建Agent、发送消息、检索Archival Memory)",
    "9. 配置监控告警和日志采集",
    "10. 编写运维文档和应急预案"
  ],

  "references": {
    "code_analysis": [
      "pyproject.toml - 依赖关系和版本要求",
      "Dockerfile - 容器镜像构建",
      "compose.yaml - 默认部署架构",
      "settings.py - 配置管理(数据库、LLM、Redis)",
      "schemas/enums.py - VectorDBProvider枚举定义",
      "schemas/passage.py - 向量存储实现",
      "schemas/archive.py - Archival Memory结构",
      "database_utils.py - 数据库URI处理",
      "constants.py - 默认配置常量"
    ],
    "documentation": [
      "architecture.md - 架构设计文档",
      "cloud-needs.md - 云服务需求分析",
      "meta.json - 项目元数据"
    ],
    "external": [
      "华为云RDS for PostgreSQL文档",
      "华为云CCE Kubernetes文档",
      "华为云ModelArts推理服务文档",
      "昇腾CANN开发文档",
      "pgvector官方文档"
    ]
  }
}
